{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f2182aa-7cbb-4866-86ab-1c37a161d6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "account_id                                                  -> '607916531205'\n",
      "alarm_name_failure                                          -> 'FlightDelayEndpointFailureAlarm'\n",
      "alarm_name_latency                                          -> 'FlightDelayEndpointLatencyAlarm'\n",
      "baseline_dataset_path                                       -> 's3://sagemaker-us-east-1-607916531205/data_captur\n",
      "baseline_model_logistic_path                                -> 'baseline_model_logistic.pkl'\n",
      "baseline_model_path                                         -> 'baseline_model.pkl'\n",
      "baseline_results_uri                                        -> 's3://sagemaker-us-east-1-607916531205/baseline_re\n",
      "create_base_csv_athena_db                                   -> True\n",
      "create_base_csv_athena_table                                -> True\n",
      "database_name                                               -> 'db_airline_delay_cause'\n",
      "dev_feature_group_name                                      -> 'airline_delay_features_dev'\n",
      "dev_feature_store_table                                     -> 'airline_delay_features_dev_1740273029'\n",
      "dev_s3_path                                                 -> 's3://sagemaker-us-east-1-607916531205/data/develo\n",
      "dev_s3_uri                                                  -> 's3://sagemaker-us-east-1-607916531205/feature-sto\n",
      "dev_table_name                                              -> 'development_data'\n",
      "drift_thresholds                                            -> {'_c0': 1740273202.9792986, '_c1': 2017.4840923430\n",
      "endpoint_name_batch_transform                               -> 'flight-delay-xgboost-endpoint-with-batch-transfor\n",
      "endpoint_name_single_request                                -> 'flight-delay-xgboost-endpoint-single-request'\n",
      "failure_threshold                                           -> 0.05\n",
      "flight_delay_data_quality_monitor_schedule_name             -> 'FlightDelayDataQualityMonitor'\n",
      "flight_delay_drift_monitor_schedule_name                    -> 'FlightDelayMonitor'\n",
      "latency_threshold                                           -> 2.0\n",
      "model_monitor                                               -> '<unavailable>'\n",
      "monitor_schedule_name                                       -> 'FlightDelayDataQualityMonitor'\n",
      "packages_installed                                          -> True\n",
      "prod_feature_group_name                                     -> 'airline_delay_features_prod'\n",
      "prod_feature_store_table                                    -> 'airline_delay_features_prod_1740273120'\n",
      "prod_s3_path                                                -> 's3://sagemaker-us-east-1-607916531205/data/produc\n",
      "prod_s3_uri                                                 -> 's3://sagemaker-us-east-1-607916531205/feature-sto\n",
      "prod_table_name                                             -> 'production_data'\n",
      "raw_table_name                                              -> 'airline_delay_cause_csv_raw'\n",
      "region                                                      -> 'us-east-1'\n",
      "role                                                        -> 'arn:aws:iam::607916531205:role/LabRole'\n",
      "s3_csv_private_path                                         -> 's3://sagemaker-us-east-1-607916531205/airline-del\n",
      "s3_staging_dir                                              -> 's3://sagemaker-us-east-1-607916531205/athena/stag\n",
      "setup_s3_bucket_passed                                      -> True\n"
     ]
    }
   ],
   "source": [
    "%store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e58ad78f-c08b-400a-b9b1-d8c1ac4ed44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Stored variables loaded (if available).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import numpy as np  # ‚úÖ Fix: Import numpy for drift threshold calculations\n",
    "import boto3  # ‚úÖ Import boto3 for AWS clients\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# ‚úÖ Initialize AWS Clients\n",
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "s3_client = boto3.client(\"s3\")\n",
    "athena_client = boto3.client(\"athena\")\n",
    "glue_client = boto3.client(\"glue\")\n",
    "cw_client = boto3.client(\"cloudwatch\")  # ‚úÖ Added CloudWatch client\n",
    "\n",
    "# ‚úÖ Retrieve stored variables safely, defaulting to None\n",
    "stored_variables = [\n",
    "    \"dev_feature_store_table\", \"prod_feature_store_table\", \n",
    "    \"dev_feature_group_name\", \"prod_feature_group_name\",\n",
    "    \"baseline_model_path\", \"baseline_model_logistic_path\",\n",
    "    \"endpoint_name_single_request\", \"endpoint_name_batch_transform\",\n",
    "    \"flight_delay_data_quality_monitor_schedule_name\",\n",
    "    \"flight_delay_drift_monitor_schedule_name\",\n",
    "    \"alarm_name_latency\",\n",
    "    \"alarm_name_failure\",\n",
    "    \"latency_threshold\",\n",
    "    \"failure_threshold\",\n",
    "    \"monitor_schedule_name\",\n",
    "    \"model_drift_alarm_name\"\n",
    "]\n",
    "\n",
    "# ‚úÖ Ensure all variables exist, setting them to None if not found in %store\n",
    "for var in stored_variables:\n",
    "    try:\n",
    "        %store -r {var}\n",
    "    except KeyError:\n",
    "        print(f\"‚ö†Ô∏è Warning: `{var}` is not stored. Defaulting to None.\")\n",
    "        globals()[var] = None  # Explicitly set missing variables to None\n",
    "\n",
    "print(\"‚úÖ Stored variables loaded (if available).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d1cfafe-3fcc-4a33-9495-dc8060bd5547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Delete CSV, JSON, and PKL Files from Root Directory\n",
    "def delete_root_files():\n",
    "    \"\"\"\n",
    "    Deletes all .csv, .json, and .pkl files from the root directory.\n",
    "    \"\"\"\n",
    "    extensions_to_remove = [\"csv\", \"json\", \"pkl\"]\n",
    "    files_deleted = 0\n",
    "\n",
    "    for ext in extensions_to_remove:\n",
    "        files = glob.glob(f'./*.{ext}')  # Only files in the root directory\n",
    "        for file in files:\n",
    "            try:\n",
    "                os.remove(file)\n",
    "                print(f\"üóëÔ∏è Deleted: {file}\")\n",
    "                files_deleted += 1\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error deleting {file}: {e}\")\n",
    "\n",
    "    if files_deleted == 0:\n",
    "        print(\"‚úÖ No CSV, JSON, or PKL files found in root directory.\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Deleted {files_deleted} files from root directory.\")\n",
    "\n",
    "# ‚úÖ Delete Feature Groups\n",
    "def delete_feature_groups():\n",
    "    for feature_group_name in [dev_feature_group_name, prod_feature_group_name]:\n",
    "        if not feature_group_name:\n",
    "            continue  # Skip if no feature group name\n",
    "\n",
    "        try:\n",
    "            existing_groups = sagemaker_client.list_feature_groups()['FeatureGroupSummaries']\n",
    "            if feature_group_name in [fg['FeatureGroupName'] for fg in existing_groups]:\n",
    "                print(f\"üöÄ Deleting Feature Group `{feature_group_name}`...\")\n",
    "                sagemaker_client.delete_feature_group(FeatureGroupName=feature_group_name)\n",
    "                time.sleep(5)  # Allow deletion to complete\n",
    "                print(f\"‚úÖ Feature Group `{feature_group_name}` deleted.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error deleting `{feature_group_name}`: {e}\")\n",
    "\n",
    "# ‚úÖ Delete Model Files\n",
    "def delete_model_files():\n",
    "    for model_path in [baseline_model_path, baseline_model_logistic_path]:\n",
    "        if model_path and os.path.exists(model_path):\n",
    "            try:\n",
    "                os.remove(model_path)\n",
    "                print(f\"üóëÔ∏è Deleted model file: {model_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error deleting `{model_path}`: {e}\")\n",
    "\n",
    "# ‚úÖ Delete SageMaker Endpoints (Single Request & Batch Transform)\n",
    "def delete_sagemaker_endpoints():\n",
    "    endpoint_names = [name for name in [endpoint_name_single_request, endpoint_name_batch_transform] if name is not None]\n",
    "\n",
    "    if not endpoint_names:\n",
    "        print(\"‚úÖ No SageMaker endpoints to delete.\")\n",
    "        return\n",
    "\n",
    "    for endpoint_name in endpoint_names:\n",
    "        try:\n",
    "            response = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "            if response[\"EndpointStatus\"] in [\"Creating\", \"InService\", \"RollingBack\", \"Updating\"]:\n",
    "                print(f\"üöÄ Deleting `{endpoint_name}`...\")\n",
    "                sagemaker_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "                time.sleep(5)  # Allow deletion to complete\n",
    "                print(f\"‚úÖ Endpoint `{endpoint_name}` deleted.\")\n",
    "        except ClientError:\n",
    "            print(f\"‚ö†Ô∏è Endpoint `{endpoint_name}` not found. Skipping...\")\n",
    "\n",
    "# ‚úÖ Delete SageMaker Models\n",
    "def delete_sagemaker_models():\n",
    "    try:\n",
    "        models = sagemaker_client.list_models()[\"Models\"]\n",
    "        model_names = [model[\"ModelName\"] for model in models]\n",
    "\n",
    "        if model_names:\n",
    "            print(f\"üöÄ Deleting {len(model_names)} SageMaker models...\")\n",
    "            for model_name in model_names:\n",
    "                sagemaker_client.delete_model(ModelName=model_name)\n",
    "                print(f\"‚úÖ Deleted model: {model_name}\")\n",
    "        else:\n",
    "            print(\"‚úÖ No SageMaker models found.\")\n",
    "    except ClientError as e:\n",
    "        print(f\"‚ùå Error deleting models: {e}\")\n",
    "\n",
    "# ‚úÖ Stop Ongoing SageMaker Batch Transform Jobs (Completed jobs remain in history)\n",
    "def stop_sagemaker_batch_jobs():\n",
    "    try:\n",
    "        batch_jobs = sagemaker_client.list_transform_jobs()[\"TransformJobSummaries\"]\n",
    "        running_jobs = [job[\"TransformJobName\"] for job in batch_jobs if job[\"TransformJobStatus\"] in [\"InProgress\", \"Stopping\"]]\n",
    "        completed_jobs = [job[\"TransformJobName\"] for job in batch_jobs if job[\"TransformJobStatus\"] == \"Completed\"]\n",
    "\n",
    "        if running_jobs:\n",
    "            print(f\"üöÄ Stopping {len(running_jobs)} running SageMaker batch jobs...\")\n",
    "            for job_name in running_jobs:\n",
    "                sagemaker_client.stop_transform_job(TransformJobName=job_name)\n",
    "                print(f\"‚úÖ Stopped batch job: {job_name}\")\n",
    "        else:\n",
    "            print(\"‚úÖ No running batch jobs to stop.\")\n",
    "\n",
    "        if completed_jobs:\n",
    "            print(f\"‚ÑπÔ∏è {len(completed_jobs)} completed batch jobs remain in history (cannot be deleted).\")\n",
    "\n",
    "    except ClientError as e:\n",
    "        print(f\"‚ùå Error stopping batch jobs: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# ‚úÖ Delete All Remaining S3 Files\n",
    "def delete_s3_files():\n",
    "    try:\n",
    "        print(f\"üîç Checking S3 for files to delete in `{bucket}`...\")\n",
    "        objects = s3_client.list_objects_v2(Bucket=bucket)\n",
    "\n",
    "        if \"Contents\" in objects:\n",
    "            print(f\"üöÄ Deleting all {len(objects['Contents'])} files in `{bucket}`...\")\n",
    "            objects_to_delete = [{\"Key\": obj[\"Key\"]} for obj in objects[\"Contents\"]]\n",
    "            s3_client.delete_objects(Bucket=bucket, Delete={\"Objects\": objects_to_delete})\n",
    "            print(f\"‚úÖ All S3 files deleted.\")\n",
    "        else:\n",
    "            print(f\"‚úÖ No files found in S3 bucket.\")\n",
    "    except ClientError as e:\n",
    "        print(f\"‚ùå Error deleting S3 files: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# ‚úÖ Delete Batch Transform Files in S3\n",
    "def delete_s3_batch_files():\n",
    "    batch_s3_path = f\"{prefix}/batch-output/\"\n",
    "    try:\n",
    "        objects = s3_client.list_objects_v2(Bucket=bucket, Prefix=batch_s3_path)\n",
    "        if \"Contents\" in objects:\n",
    "            print(f\"üöÄ Deleting batch files in `{batch_s3_path}`...\")\n",
    "            s3_client.delete_objects(Bucket=bucket, Delete={\"Objects\": [{\"Key\": obj[\"Key\"]} for obj in objects[\"Contents\"]]})\n",
    "            print(\"‚úÖ Batch files deleted.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error deleting batch files: {e}\")\n",
    "\n",
    "# ‚úÖ Drop Feature Store Tables in Athena\n",
    "def drop_feature_store_tables():\n",
    "    try:\n",
    "        tables = athena_client.list_table_metadata(CatalogName=\"AwsDataCatalog\", DatabaseName=ATHENA_DATABASE)[\"TableMetadataList\"]\n",
    "        table_names = [table[\"Name\"] for table in tables if \"airline_delay_features\" in table[\"Name\"]]\n",
    "\n",
    "        if table_names:\n",
    "            print(f\"üöÄ Dropping {len(table_names)} tables from Athena...\")\n",
    "            for table in table_names:\n",
    "                athena_client.start_query_execution(\n",
    "                    QueryString=f\"DROP TABLE IF EXISTS {ATHENA_DATABASE}.{table};\",\n",
    "                    QueryExecutionContext={\"Database\": ATHENA_DATABASE},\n",
    "                    ResultConfiguration={\"OutputLocation\": f\"s3://{bucket}/athena-query-results/\"}\n",
    "                )\n",
    "                print(f\"‚úÖ Dropped `{table}`.\")\n",
    "                time.sleep(2)\n",
    "        else:\n",
    "            print(\"‚úÖ No old feature store tables found in Athena.\")\n",
    "    except ClientError as e:\n",
    "        print(f\"‚ùå Error dropping Athena tables: {e}\")\n",
    "\n",
    "# ‚úÖ Delete All Glue Databases (except `default`)\n",
    "def delete_glue_databases():\n",
    "    try:\n",
    "        glue_databases = glue_client.get_databases()[\"DatabaseList\"]\n",
    "        glue_db_names = [db[\"Name\"] for db in glue_databases if db[\"Name\"] != \"default\"]  # Avoid deleting `default`\n",
    "\n",
    "        if glue_db_names:\n",
    "            print(f\"üöÄ Deleting {len(glue_db_names)} Glue databases...\")\n",
    "            for db in glue_db_names:\n",
    "                glue_client.delete_database(Name=db)\n",
    "                print(f\"‚úÖ Deleted Glue database: {db}\")\n",
    "        else:\n",
    "            print(\"‚úÖ No unnecessary Glue databases found.\")\n",
    "    except ClientError as e:\n",
    "        print(f\"‚ùå Error deleting Glue databases: {e}\")\n",
    "\n",
    "\n",
    "# ‚úÖ Delete Feature Store S3 Files\n",
    "def delete_s3_feature_store_files():\n",
    "    feature_store_prefix = \"feature-store/\"\n",
    "    try:\n",
    "        objects = s3_client.list_objects_v2(Bucket=bucket, Prefix=feature_store_prefix)\n",
    "        if \"Contents\" in objects:\n",
    "            print(f\"üöÄ Deleting feature store files in `{feature_store_prefix}`...\")\n",
    "            s3_client.delete_objects(Bucket=bucket, Delete={\"Objects\": [{\"Key\": obj[\"Key\"]} for obj in objects[\"Contents\"]]})\n",
    "            print(\"‚úÖ Feature store files deleted.\")\n",
    "        else:\n",
    "            print(\"‚úÖ No feature store files found.\")\n",
    "    except ClientError as e:\n",
    "        print(f\"‚ùå Error deleting feature store files: {e}\")\n",
    "\n",
    "# ‚úÖ Delete SageMaker Training & Debugger Output Files\n",
    "def delete_s3_training_output():\n",
    "    training_output_prefix = \"flight-delay-prediction-xgboost/output/\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"üîç Checking S3 for training output files in `{training_output_prefix}`...\")\n",
    "        response = s3_client.list_objects_v2(Bucket=bucket, Prefix=training_output_prefix)\n",
    "\n",
    "        if \"Contents\" in response:\n",
    "            print(f\"üöÄ Deleting all {len(response['Contents'])} training output files in `{training_output_prefix}`...\")\n",
    "            objects_to_delete = [{\"Key\": obj[\"Key\"]} for obj in response[\"Contents\"]]\n",
    "            s3_client.delete_objects(Bucket=bucket, Delete={\"Objects\": objects_to_delete})\n",
    "            print(f\"‚úÖ Training output files deleted.\")\n",
    "        else:\n",
    "            print(f\"‚úÖ No training output files found in S3 bucket.\")\n",
    "    except ClientError as e:\n",
    "        print(f\"‚ùå Error deleting training output files: {e}\")\n",
    "\n",
    "# ‚úÖ Delete Monitoring Schedules\n",
    "def delete_monitoring_schedules():\n",
    "    for schedule_name in [flight_delay_drift_monitor_schedule_name, flight_delay_data_quality_monitor_schedule_name]:\n",
    "        if not schedule_name:\n",
    "            continue  # Skip if no schedule name\n",
    "\n",
    "        try:\n",
    "            existing_schedules = sagemaker_client.list_monitoring_schedules()['MonitoringScheduleSummaries']\n",
    "            if schedule_name in [schedule['MonitoringScheduleName'] for schedule in existing_schedules]:\n",
    "                print(f\"üöÄ Deleting Monitoring Schedule `{schedule_name}`...\")\n",
    "                sagemaker_client.delete_monitoring_schedule(MonitoringScheduleName=schedule_name)  # ‚úÖ Fix: Use sagemaker_client\n",
    "                time.sleep(5)  # Allow deletion to complete\n",
    "                print(f\"‚úÖ Monitoring Schedule `{schedule_name}` deleted.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error deleting `{schedule_name}`: {e}\")\n",
    "\n",
    "# ‚úÖ Delete CloudWatch Alarms\n",
    "def delete_cloudwatch_alarms():\n",
    "    alarms_to_delete = [\n",
    "        alarm_name_latency,  # ‚úÖ Fix: Correct variable name from %store\n",
    "        alarm_name_failure,  # ‚úÖ Fix: Correct variable name from %store\n",
    "        model_drift_alarm_name  # ‚úÖ Fix: Added FlightDelayModelDriftAlarm for deletion\n",
    "    ]\n",
    "    \n",
    "    for alarm_name in alarms_to_delete:\n",
    "        if alarm_name:\n",
    "            try:\n",
    "                print(f\"üöÄ Deleting CloudWatch Alarm `{alarm_name}`...\")\n",
    "                cw_client.delete_alarms(AlarmNames=[alarm_name])\n",
    "                print(f\"‚úÖ CloudWatch Alarm `{alarm_name}` deleted.\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error deleting alarm `{alarm_name}`: {e}\")\n",
    "\n",
    "# ‚úÖ Drop All Athena Tables from All Databases\n",
    "def drop_feature_store_tables():\n",
    "    try:\n",
    "        # ‚úÖ List all databases in Athena\n",
    "        databases = athena_client.list_databases(CatalogName=\"AwsDataCatalog\")[\"DatabaseList\"]\n",
    "        database_names = [db[\"Name\"] for db in databases]\n",
    "\n",
    "        for database in database_names:\n",
    "            # ‚úÖ List tables in the database\n",
    "            tables = athena_client.list_table_metadata(CatalogName=\"AwsDataCatalog\", DatabaseName=database)[\"TableMetadataList\"]\n",
    "            table_names = [table[\"Name\"] for table in tables]\n",
    "\n",
    "            if table_names:\n",
    "                print(f\"üöÄ Dropping {len(table_names)} tables from Athena database `{database}`...\")\n",
    "                for table in table_names:\n",
    "                    query = f\"DROP TABLE IF EXISTS {database}.{table};\"\n",
    "                    athena_client.start_query_execution(\n",
    "                        QueryString=query,\n",
    "                        QueryExecutionContext={\"Database\": database},\n",
    "                        ResultConfiguration={\"OutputLocation\": f\"s3://{bucket}/athena-query-results/\"}\n",
    "                    )\n",
    "                    print(f\"‚úÖ Dropped `{table}` from `{database}`.\")\n",
    "                    time.sleep(2)\n",
    "            else:\n",
    "                print(f\"‚úÖ No tables found in Athena database `{database}`.\")\n",
    "\n",
    "    except ClientError as e:\n",
    "        print(f\"‚ùå Error dropping Athena tables: {e}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64363979-94b5-4b5a-a7a2-87f682fe6cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ **Starting Full Cleanup...**\n",
      "\n",
      "üöÄ Deleting CloudWatch Alarm `FlightDelayEndpointLatencyAlarm`...\n",
      "‚úÖ CloudWatch Alarm `FlightDelayEndpointLatencyAlarm` deleted.\n",
      "üöÄ Deleting CloudWatch Alarm `FlightDelayEndpointFailureAlarm`...\n",
      "‚úÖ CloudWatch Alarm `FlightDelayEndpointFailureAlarm` deleted.\n",
      "üöÄ Deleting CloudWatch Alarm `FlightDelayModelDriftAlarm`...\n",
      "‚úÖ CloudWatch Alarm `FlightDelayModelDriftAlarm` deleted.\n",
      "‚úÖ No SageMaker models found.\n",
      "‚ö†Ô∏è Endpoint `flight-delay-xgboost-endpoint-single-request` not found. Skipping...\n",
      "‚ö†Ô∏è Endpoint `flight-delay-xgboost-endpoint-with-batch-transform` not found. Skipping...\n",
      "‚úÖ No running batch jobs to stop.\n",
      "‚ÑπÔ∏è 10 completed batch jobs remain in history (cannot be deleted).\n",
      "‚úÖ No feature store files found.\n",
      "üöÄ Dropping 3 tables from Athena database `db_airline_delay_cause`...\n",
      "‚úÖ Dropped `airline_delay_cause_csv_raw` from `db_airline_delay_cause`.\n",
      "‚úÖ Dropped `development_data` from `db_airline_delay_cause`.\n",
      "‚úÖ Dropped `production_data` from `db_airline_delay_cause`.\n",
      "‚úÖ No tables found in Athena database `default`.\n",
      "‚úÖ No tables found in Athena database `sagemaker_featurestore`.\n",
      "üöÄ Deleting 2 Glue databases...\n",
      "‚úÖ Deleted Glue database: db_airline_delay_cause\n",
      "‚úÖ Deleted Glue database: sagemaker_featurestore\n",
      "üîç Checking S3 for training output files in `flight-delay-prediction-xgboost/output/`...\n",
      "‚úÖ No training output files found in S3 bucket.\n",
      "üîç Checking S3 for files to delete in `aws-athena-query-results-607916531205-us-east-1`...\n",
      "üöÄ Deleting all 6 files in `aws-athena-query-results-607916531205-us-east-1`...\n",
      "‚úÖ All S3 files deleted.\n",
      "‚úÖ No CSV, JSON, or PKL files found in root directory.\n",
      "\n",
      "‚úÖ **Cleanup completed successfully!**\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Run Full Cleanup\n",
    "def clean_state():\n",
    "    print(\"\\nüöÄ **Starting Full Cleanup...**\\n\")\n",
    "\n",
    "    # ‚úÖ Step 1: Delete SageMaker-related resources in dependency order\n",
    "    delete_monitoring_schedules()  # Must delete first before endpoints/models\n",
    "    delete_cloudwatch_alarms()\n",
    "    delete_feature_groups()\n",
    "    delete_sagemaker_models()  # Must be deleted before endpoints\n",
    "    delete_sagemaker_endpoints()\n",
    "    stop_sagemaker_batch_jobs()  # Stop any running batch jobs\n",
    "\n",
    "    # ‚úÖ Step 2: Clean up storage in order of dependencies\n",
    "    delete_model_files()  # Remove locally stored model files\n",
    "    delete_s3_batch_files()  # Delete batch transform outputs before main S3 cleanup\n",
    "    delete_s3_feature_store_files()  # Delete feature store S3 data before dropping tables\n",
    "\n",
    "    # ‚úÖ Step 3: Delete Athena & Glue-related resources\n",
    "    drop_feature_store_tables()  # Drop tables first before deleting the database\n",
    "    delete_glue_databases()  # Remove Glue databases\n",
    "\n",
    "    # ‚úÖ Step 4: Delete remaining S3 files (now safe to remove)\n",
    "    delete_s3_training_output()\n",
    "    delete_s3_files()\n",
    "    delete_root_files()\n",
    "\n",
    "    print(\"\\n‚úÖ **Cleanup completed successfully!**\")\n",
    "\n",
    "# ‚úÖ Execute cleanup\n",
    "clean_state()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a35eb5f-73b7-46ac-a8c9-671328c04ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Removed `dev_feature_store_table` from %store.\n",
      "üßπ Removed `prod_feature_store_table` from %store.\n",
      "üßπ Removed `dev_feature_group_name` from %store.\n",
      "üßπ Removed `prod_feature_group_name` from %store.\n",
      "üßπ Removed `baseline_model_path` from %store.\n",
      "üßπ Removed `baseline_model_logistic_path` from %store.\n",
      "üßπ Removed `endpoint_name_single_request` from %store.\n",
      "üßπ Removed `endpoint_name_batch_transform` from %store.\n",
      "üßπ Removed `flight_delay_data_quality_monitor_schedule_name` from %store.\n",
      "üßπ Removed `flight_delay_drift_monitor_schedule_name` from %store.\n",
      "üßπ Removed `alarm_name_latency` from %store.\n",
      "üßπ Removed `alarm_name_failure` from %store.\n",
      "üßπ Removed `latency_threshold` from %store.\n",
      "üßπ Removed `failure_threshold` from %store.\n",
      "üßπ Removed `monitor_schedule_name` from %store.\n",
      "üßπ Removed `model_drift_alarm_name` from %store.\n",
      "üßπ Removed `account_id` from %store.\n",
      "üßπ Removed `baseline_dataset_path` from %store.\n",
      "üßπ Removed `baseline_results_uri` from %store.\n",
      "üßπ Removed `create_base_csv_athena_db` from %store.\n",
      "üßπ Removed `create_base_csv_athena_table` from %store.\n",
      "üßπ Removed `database_name` from %store.\n",
      "üßπ Removed `dev_s3_path` from %store.\n",
      "üßπ Removed `dev_s3_uri` from %store.\n",
      "üßπ Removed `dev_table_name` from %store.\n",
      "üßπ Removed `drift_thresholds` from %store.\n",
      "üßπ Removed `model_monitor` from %store.\n",
      "üßπ Removed `packages_installed` from %store.\n",
      "üßπ Removed `prod_s3_path` from %store.\n",
      "üßπ Removed `prod_s3_uri` from %store.\n",
      "üßπ Removed `prod_table_name` from %store.\n",
      "üßπ Removed `raw_table_name` from %store.\n",
      "üßπ Removed `region` from %store.\n",
      "üßπ Removed `role` from %store.\n",
      "üßπ Removed `s3_csv_private_path` from %store.\n",
      "üßπ Removed `s3_staging_dir` from %store.\n",
      "üßπ Removed `setup_s3_bucket_passed` from %store.\n",
      "Stored variables and their in-db values:\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ List of all stored variables to delete\n",
    "all_stored_variables = [\n",
    "    \"dev_feature_store_table\", \"prod_feature_store_table\", \n",
    "    \"dev_feature_group_name\", \"prod_feature_group_name\",\n",
    "    \"baseline_model_path\", \"baseline_model_logistic_path\",\n",
    "    \"endpoint_name_single_request\", \"endpoint_name_batch_transform\",\n",
    "    \"flight_delay_data_quality_monitor_schedule_name\",\n",
    "    \"flight_delay_drift_monitor_schedule_name\",\n",
    "    \"alarm_name_latency\", \"alarm_name_failure\",\n",
    "    \"latency_threshold\", \"failure_threshold\",\n",
    "    \"monitor_schedule_name\", \"model_drift_alarm_name\",\n",
    "    \"account_id\", \"baseline_dataset_path\", \"baseline_results_uri\",\n",
    "    \"create_base_csv_athena_db\", \"create_base_csv_athena_table\",\n",
    "    \"database_name\", \"dev_s3_path\", \"dev_s3_uri\", \"dev_table_name\",\n",
    "    \"drift_thresholds\", \"model_monitor\", \"packages_installed\",\n",
    "    \"prod_s3_path\", \"prod_s3_uri\", \"prod_table_name\",\n",
    "    \"raw_table_name\", \"region\", \"role\",\n",
    "    \"s3_csv_private_path\", \"s3_staging_dir\", \"setup_s3_bucket_passed\"\n",
    "]\n",
    "\n",
    "# ‚úÖ Remove all stored variables\n",
    "def clear_all_stored_variables():\n",
    "    for var in all_stored_variables:\n",
    "        try:\n",
    "            %store -d {var}  # Delete from %store\n",
    "            print(f\"üßπ Removed `{var}` from %store.\")\n",
    "        except Exception:\n",
    "            print(f\"‚ö†Ô∏è `{var}` was not in %store. Skipping...\")\n",
    "\n",
    "# ‚úÖ Execute cleanup\n",
    "clear_all_stored_variables()\n",
    "\n",
    "# ‚úÖ Verify if all variables are removed\n",
    "%store\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe1e013-632f-4f86-8001-1b5ffe1a741b",
   "metadata": {},
   "source": [
    "# Use code below to check what else is on your system and whether something was left behind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cacef9e-d7bd-4026-888c-5f9faee81daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- üìå AWS Resource Overview ---\n",
      "\n",
      "üìå **Athena Databases:**\n",
      "   - default\n",
      "\n",
      "üìå **Tables in Athena Database: `default`**\n",
      "   ‚ùå No tables found in this database.\n",
      "\n",
      "üìå **Feature Store Groups:**\n",
      "   ‚ùå No Feature Groups found.\n",
      "\n",
      "üìå **SageMaker Endpoints:**\n",
      "   ‚ùå No SageMaker Endpoints found.\n",
      "\n",
      "üìå **SageMaker Models:**\n",
      "   ‚ùå No SageMaker Models found.\n",
      "\n",
      "üìå **SageMaker Model Monitoring Schedules:**\n",
      "   ‚ùå No Monitoring Schedules found.\n",
      "\n",
      "üìå **SageMaker Batch Transform Jobs:**\n",
      "   - sagemaker-xgboost-2025-02-23-01-55-30-697\n",
      "   - sagemaker-xgboost-2025-02-19-05-26-04-620\n",
      "   - pipelines-lum39tvg22zt-AbaloneTransform-SdJZQXw6zR\n",
      "   - pipelines-b9q304vfzej0-AbaloneTransform-hpPnA9nR73\n",
      "   - pipelines-xw5ukyv44cda-AbaloneTransform-rvefu7xYmu\n",
      "   - sagemaker-xgboost-2025-01-31-08-39-00-505\n",
      "   - sagemaker-xgboost-2025-01-31-08-31-25-431\n",
      "   - sagemaker-xgboost-2025-01-31-08-24-20-187\n",
      "   - sagemaker-xgboost-2025-01-31-08-09-06-879\n",
      "   - sagemaker-xgboost-2025-01-31-07-59-41-193\n",
      "\n",
      "üìå **S3 Files in Bucket `aws-athena-query-results-607916531205-us-east-1`:**\n",
      "   ‚ùå No files found.\n",
      "\n",
      "üìå **Glue Databases:**\n",
      "   - default\n",
      "\n",
      "üìå **CloudWatch Alarms:**\n",
      "   ‚ùå No CloudWatch Alarms found.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "from pyathena import connect\n",
    "\n",
    "# ‚úÖ Initialize AWS Session\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "sagemaker_session = boto3.Session()  # ‚úÖ Fix: Corrected SageMaker session initialization\n",
    "\n",
    "# ‚úÖ Use SageMaker's default bucket\n",
    "bucket = sagemaker_session.client(\"s3\").list_buckets()[\"Buckets\"][0][\"Name\"]\n",
    "\n",
    "# ‚úÖ Set up Athena connection\n",
    "s3_staging_dir = f's3://{bucket}/athena-query-results/'\n",
    "conn = connect(s3_staging_dir=s3_staging_dir, region_name=region)\n",
    "\n",
    "# ‚úÖ Initialize AWS clients\n",
    "s3_client = boto3.client(\"s3\", region_name=region)\n",
    "athena_client = boto3.client(\"athena\", region_name=region)\n",
    "sagemaker_client = boto3.client(\"sagemaker\", region_name=region)\n",
    "glue_client = boto3.client(\"glue\", region_name=region)\n",
    "cw_client = boto3.client(\"cloudwatch\", region_name=region)  # ‚úÖ Added CloudWatch client\n",
    "\n",
    "# ‚úÖ Function to list AWS resources\n",
    "def list_aws_resources():\n",
    "    print(\"\\n--- üìå AWS Resource Overview ---\")\n",
    "\n",
    "    # ‚úÖ List Athena Databases\n",
    "    try:\n",
    "        databases = athena_client.list_databases(CatalogName=\"AwsDataCatalog\")[\"DatabaseList\"]\n",
    "        database_names = [db[\"Name\"] for db in databases]\n",
    "        print(\"\\nüìå **Athena Databases:**\")\n",
    "        for db in database_names:\n",
    "            print(f\"   - {db}\")\n",
    "    except ClientError as e:\n",
    "        print(\"‚ùå Error listing Athena databases:\", e)\n",
    "        database_names = []  # Ensure it doesn't break the next step\n",
    "\n",
    "    # ‚úÖ List Athena Tables Per Database\n",
    "    for database in database_names:\n",
    "        try:\n",
    "            tables = athena_client.list_table_metadata(CatalogName=\"AwsDataCatalog\", DatabaseName=database)[\"TableMetadataList\"]\n",
    "            table_names = [table[\"Name\"] for table in tables]\n",
    "\n",
    "            print(f\"\\nüìå **Tables in Athena Database: `{database}`**\")\n",
    "            if table_names:\n",
    "                for table in table_names:\n",
    "                    print(f\"   - {table}\")\n",
    "            else:\n",
    "                print(\"   ‚ùå No tables found in this database.\")\n",
    "\n",
    "        except ClientError as e:\n",
    "            print(f\"‚ùå Error listing tables in `{database}`:\", e)\n",
    "\n",
    "    # ‚úÖ List Feature Store Groups\n",
    "    try:\n",
    "        feature_groups = sagemaker_client.list_feature_groups()[\"FeatureGroupSummaries\"]\n",
    "        feature_group_names = [fg[\"FeatureGroupName\"] for fg in feature_groups]\n",
    "        print(\"\\nüìå **Feature Store Groups:**\")\n",
    "        if feature_group_names:\n",
    "            for fg in feature_group_names:\n",
    "                print(f\"   - {fg}\")\n",
    "        else:\n",
    "            print(\"   ‚ùå No Feature Groups found.\")\n",
    "    except ClientError as e:\n",
    "        print(\"‚ùå Error listing Feature Groups:\", e)\n",
    "\n",
    "    # ‚úÖ List Deployed SageMaker Endpoints\n",
    "    try:\n",
    "        endpoints = sagemaker_client.list_endpoints()[\"Endpoints\"]\n",
    "        endpoint_names = [ep[\"EndpointName\"] for ep in endpoints]\n",
    "        print(\"\\nüìå **SageMaker Endpoints:**\")\n",
    "        if endpoint_names:\n",
    "            for ep in endpoint_names:\n",
    "                print(f\"   - {ep}\")\n",
    "        else:\n",
    "            print(\"   ‚ùå No SageMaker Endpoints found.\")\n",
    "    except ClientError as e:\n",
    "        print(\"‚ùå Error listing SageMaker Endpoints:\", e)\n",
    "\n",
    "    # ‚úÖ List Deployed SageMaker Models\n",
    "    try:\n",
    "        models = sagemaker_client.list_models()[\"Models\"]\n",
    "        model_names = [model[\"ModelName\"] for model in models]\n",
    "        print(\"\\nüìå **SageMaker Models:**\")\n",
    "        if model_names:\n",
    "            for model in model_names:\n",
    "                print(f\"   - {model}\")\n",
    "        else:\n",
    "            print(\"   ‚ùå No SageMaker Models found.\")\n",
    "    except ClientError as e:\n",
    "        print(\"‚ùå Error listing SageMaker Models:\", e)\n",
    "\n",
    "    # ‚úÖ List SageMaker Model Monitoring Schedules\n",
    "    try:\n",
    "        schedules = sagemaker_client.list_monitoring_schedules()[\"MonitoringScheduleSummaries\"]\n",
    "        schedule_names = [schedule[\"MonitoringScheduleName\"] for schedule in schedules]\n",
    "        print(\"\\nüìå **SageMaker Model Monitoring Schedules:**\")\n",
    "        if schedule_names:\n",
    "            for schedule in schedule_names:\n",
    "                print(f\"   - {schedule}\")\n",
    "        else:\n",
    "            print(\"   ‚ùå No Monitoring Schedules found.\")\n",
    "    except ClientError as e:\n",
    "        print(\"‚ùå Error listing SageMaker Monitoring Schedules:\", e)\n",
    "\n",
    "    # ‚úÖ List Batch Transform Jobs\n",
    "    try:\n",
    "        transform_jobs = sagemaker_client.list_transform_jobs()[\"TransformJobSummaries\"]\n",
    "        batch_jobs = [job[\"TransformJobName\"] for job in transform_jobs]\n",
    "        print(\"\\nüìå **SageMaker Batch Transform Jobs:**\")\n",
    "        if batch_jobs:\n",
    "            for job in batch_jobs:\n",
    "                print(f\"   - {job}\")\n",
    "        else:\n",
    "            print(\"   ‚ùå No Batch Transform Jobs found.\")\n",
    "    except ClientError as e:\n",
    "        print(\"‚ùå Error listing Batch Transform Jobs:\", e)\n",
    "\n",
    "    # ‚úÖ List S3 Files\n",
    "    try:\n",
    "        objects = s3_client.list_objects_v2(Bucket=bucket)\n",
    "        s3_files = [obj[\"Key\"] for obj in objects.get(\"Contents\", [])]\n",
    "        print(f\"\\nüìå **S3 Files in Bucket `{bucket}`:**\")\n",
    "        if s3_files:\n",
    "            for file in s3_files[:10]:  # Show only first 10 files for readability\n",
    "                print(f\"   - {file}\")\n",
    "            if len(s3_files) > 10:\n",
    "                print(f\"   ... ({len(s3_files)} total files)\")\n",
    "        else:\n",
    "            print(\"   ‚ùå No files found.\")\n",
    "    except ClientError as e:\n",
    "        print(\"‚ùå Error listing S3 files:\", e)\n",
    "\n",
    "    # ‚úÖ List Glue Databases\n",
    "    try:\n",
    "        glue_databases = glue_client.get_databases()[\"DatabaseList\"]\n",
    "        glue_db_names = [db[\"Name\"] for db in glue_databases]\n",
    "        print(\"\\nüìå **Glue Databases:**\")\n",
    "        if glue_db_names:\n",
    "            for db in glue_db_names:\n",
    "                print(f\"   - {db}\")\n",
    "        else:\n",
    "            print(\"   ‚ùå No Glue Databases found.\")\n",
    "    except ClientError as e:\n",
    "        print(\"‚ùå Error listing Glue databases:\", e)\n",
    "\n",
    "    # ‚úÖ List CloudWatch Alarms\n",
    "    try:\n",
    "        alarms = cw_client.describe_alarms()[\"MetricAlarms\"]\n",
    "        alarm_names = [alarm[\"AlarmName\"] for alarm in alarms]\n",
    "        print(\"\\nüìå **CloudWatch Alarms:**\")\n",
    "        if alarm_names:\n",
    "            for alarm in alarm_names:\n",
    "                print(f\"   - {alarm}\")\n",
    "        else:\n",
    "            print(\"   ‚ùå No CloudWatch Alarms found.\")\n",
    "    except ClientError as e:\n",
    "        print(\"‚ùå Error listing CloudWatch Alarms:\", e)\n",
    "\n",
    "# ‚úÖ Run AWS resource listing\n",
    "list_aws_resources()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ffae52-2d45-4a8c-96fe-03d3d8588cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
