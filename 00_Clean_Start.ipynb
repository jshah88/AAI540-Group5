{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58f0a186-8f8f-400b-ab94-40e777ffcc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no stored variable or alias dev_feature_store_table\n",
      "no stored variable or alias prod_feature_store_table\n",
      "no stored variable or alias dev_feature_group_name\n",
      "no stored variable or alias prod_feature_group_name\n",
      "✅ Successfully loaded stored variables.\n"
     ]
    }
   ],
   "source": [
    "# ✅ Retrieve stored variables from previous notebooks\n",
    "%store -r dev_feature_store_table\n",
    "%store -r prod_feature_store_table\n",
    "%store -r dev_feature_group_name\n",
    "%store -r prod_feature_group_name\n",
    "\n",
    "# ✅ Verify the variables exist\n",
    "if \"dev_feature_store_table\" not in locals() or \"prod_feature_store_table\" not in locals():\n",
    "    raise ValueError(\"❌ Missing feature store table names. Run the setup notebook first!\")\n",
    "\n",
    "print(\"✅ Successfully loaded stored variables.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e58ad78f-c08b-400a-b9b1-d8c1ac4ed44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no stored variable or alias dev_feature_store_table\n",
      "no stored variable or alias prod_feature_store_table\n",
      "no stored variable or alias dev_feature_group_name\n",
      "no stored variable or alias prod_feature_group_name\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "❌ Required variables are missing. Ensure the previous notebook has been run!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# ✅ Verify that all required variables are loaded\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(var \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlocals\u001b[39m() \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdev_feature_store_table\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprod_feature_store_table\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdev_feature_group_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprod_feature_group_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m❌ Required variables are missing. Ensure the previous notebook has been run!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# ✅ Initialize AWS Session\u001b[39;00m\n\u001b[1;32m     20\u001b[0m session \u001b[38;5;241m=\u001b[39m boto3\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mSession()\n",
      "\u001b[0;31mValueError\u001b[0m: ❌ Required variables are missing. Ensure the previous notebook has been run!"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from botocore.exceptions import ClientError\n",
    "from pyathena import connect\n",
    "import time\n",
    "\n",
    "# ✅ Restore variables stored from previous notebooks\n",
    "%store -r dev_feature_store_table\n",
    "%store -r prod_feature_store_table\n",
    "%store -r dev_feature_group_name\n",
    "%store -r prod_feature_group_name\n",
    "\n",
    "# ✅ Verify that all required variables are loaded\n",
    "if not all(var in locals() for var in [\"dev_feature_store_table\", \"prod_feature_store_table\", \"dev_feature_group_name\", \"prod_feature_group_name\"]):\n",
    "    raise ValueError(\"❌ Required variables are missing. Ensure the previous notebook has been run!\")\n",
    "\n",
    "# ✅ Initialize AWS Session\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# ✅ Use SageMaker's default bucket\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "# ✅ Set up Athena connection\n",
    "s3_staging_dir = f's3://{bucket}/athena-query-results/'\n",
    "conn = connect(s3_staging_dir=s3_staging_dir, region_name=region)\n",
    "\n",
    "# ✅ Define variables\n",
    "ATHENA_DATABASE = \"sagemaker_featurestore\"\n",
    "ATHENA_TABLES_TO_DROP = [dev_feature_store_table, prod_feature_store_table]  # ✅ Fixed: Now uses stored table names\n",
    "GLUE_DATABASE_TO_DROP = \"db_airline_delay_cause\"\n",
    "\n",
    "# ✅ Initialize AWS clients\n",
    "s3_client = boto3.client(\"s3\")\n",
    "athena_client = boto3.client(\"athena\")\n",
    "sagemaker_client = boto3.client(\"sagemaker\", region_name=region)\n",
    "glue_client = boto3.client(\"glue\", region_name=region)\n",
    "\n",
    "# ✅ Feature Group Names (Restored from %store)\n",
    "DEV_FEATURE_GROUP_NAME = dev_feature_group_name\n",
    "PROD_FEATURE_GROUP_NAME = prod_feature_group_name\n",
    "\n",
    "# ✅ Delete both Dev & Prod Feature Groups\n",
    "def delete_feature_groups():\n",
    "    for feature_group_name in [DEV_FEATURE_GROUP_NAME, PROD_FEATURE_GROUP_NAME]:\n",
    "        try:\n",
    "            print(f\"🔍 Checking if Feature Group `{feature_group_name}` exists...\")\n",
    "            existing_groups = sagemaker_client.list_feature_groups()['FeatureGroupSummaries']\n",
    "            existing_group_names = [fg['FeatureGroupName'] for fg in existing_groups]\n",
    "\n",
    "            if feature_group_name in existing_group_names:\n",
    "                print(f\"🚀 Feature Group `{feature_group_name}` found. Deleting...\")\n",
    "                sagemaker_client.delete_feature_group(FeatureGroupName=feature_group_name)\n",
    "\n",
    "                # Wait until deletion is complete\n",
    "                while True:\n",
    "                    existing_groups = sagemaker_client.list_feature_groups()['FeatureGroupSummaries']\n",
    "                    existing_group_names = [fg['FeatureGroupName'] for fg in existing_groups]\n",
    "                    if feature_group_name not in existing_group_names:\n",
    "                        print(f\"✅ Feature Group `{feature_group_name}` deleted successfully.\")\n",
    "                        break\n",
    "                    print(\"⏳ Waiting for Feature Group deletion...\")\n",
    "                    time.sleep(5)\n",
    "            else:\n",
    "                print(f\"✅ Feature Group `{feature_group_name}` does not exist. No deletion needed.\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error deleting Feature Group `{feature_group_name}`: {e}\")\n",
    "\n",
    "# ✅ Run cleanup\n",
    "def clean_state():\n",
    "    print(\"\\n🚀 **Starting Full Cleanup...**\\n\")\n",
    "    delete_feature_groups()  # ✅ Now deletes both feature groups\n",
    "    print(\"\\n✅ **Cleanup completed successfully!**\")\n",
    "\n",
    "# ✅ Execute the cleanup function\n",
    "clean_state()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe1e013-632f-4f86-8001-1b5ffe1a741b",
   "metadata": {},
   "source": [
    "# Use code below to check what else is on your system and whether something was left behind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cacef9e-d7bd-4026-888c-5f9faee81daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 📌 AWS Resource Overview ---\n",
      "\n",
      "📌 **Athena Databases:**\n",
      "   - default\n",
      "\n",
      "📌 **Tables in Athena Database: `default`**\n",
      "   ❌ No tables found in this database.\n",
      "\n",
      "📌 **Feature Store Groups:**\n",
      "   ❌ No Feature Groups found.\n",
      "\n",
      "📌 **S3 Files in Bucket `{bucket}`:**\n",
      "   ❌ No files found.\n",
      "\n",
      "📌 **Glue Databases:**\n",
      "   - default\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "from pyathena import connect\n",
    "\n",
    "# ✅ Initialize AWS Session\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "sagemaker_session = boto3.Session()\n",
    "\n",
    "# ✅ Use SageMaker's default bucket\n",
    "bucket = sagemaker_session.client(\"s3\").list_buckets()[\"Buckets\"][0][\"Name\"]\n",
    "\n",
    "# ✅ Set up Athena connection\n",
    "s3_staging_dir = f's3://{bucket}/athena-query-results/'\n",
    "conn = connect(s3_staging_dir=s3_staging_dir, region_name=region)\n",
    "\n",
    "# ✅ Initialize AWS clients\n",
    "s3_client = boto3.client(\"s3\", region_name=region)\n",
    "athena_client = boto3.client(\"athena\", region_name=region)\n",
    "sagemaker_client = boto3.client(\"sagemaker\", region_name=region)\n",
    "glue_client = boto3.client(\"glue\", region_name=region)\n",
    "\n",
    "# ✅ Function to list AWS resources\n",
    "def list_aws_resources():\n",
    "    print(\"\\n--- 📌 AWS Resource Overview ---\")\n",
    "    \n",
    "    # ✅ List Athena Databases\n",
    "    try:\n",
    "        databases = athena_client.list_databases(CatalogName=\"AwsDataCatalog\")[\"DatabaseList\"]\n",
    "        database_names = [db[\"Name\"] for db in databases]\n",
    "        print(\"\\n📌 **Athena Databases:**\")\n",
    "        for db in database_names:\n",
    "            print(f\"   - {db}\")\n",
    "    except ClientError as e:\n",
    "        print(\"❌ Error listing Athena databases:\", e)\n",
    "        database_names = []  # Ensure it doesn't break the next step\n",
    "\n",
    "    # ✅ List Athena Tables Per Database\n",
    "    for database in database_names:\n",
    "        try:\n",
    "            tables = athena_client.list_table_metadata(CatalogName=\"AwsDataCatalog\", DatabaseName=database)[\"TableMetadataList\"]\n",
    "            table_names = [table[\"Name\"] for table in tables]\n",
    "\n",
    "            print(f\"\\n📌 **Tables in Athena Database: `{database}`**\")\n",
    "            if table_names:\n",
    "                for table in table_names:\n",
    "                    print(f\"   - {table}\")\n",
    "            else:\n",
    "                print(\"   ❌ No tables found in this database.\")\n",
    "\n",
    "        except ClientError as e:\n",
    "            print(f\"❌ Error listing tables in `{database}`:\", e)\n",
    "\n",
    "    # ✅ List Feature Store Groups\n",
    "    try:\n",
    "        feature_groups = sagemaker_client.list_feature_groups()[\"FeatureGroupSummaries\"]\n",
    "        feature_group_names = [fg[\"FeatureGroupName\"] for fg in feature_groups]\n",
    "        print(\"\\n📌 **Feature Store Groups:**\")\n",
    "        if feature_group_names:\n",
    "            for fg in feature_group_names:\n",
    "                print(f\"   - {fg}\")\n",
    "        else:\n",
    "            print(\"   ❌ No Feature Groups found.\")\n",
    "    except ClientError as e:\n",
    "        print(\"❌ Error listing Feature Groups:\", e)\n",
    "\n",
    "    # ✅ List S3 Files\n",
    "    try:\n",
    "        objects = s3_client.list_objects_v2(Bucket=bucket)\n",
    "        s3_files = [obj[\"Key\"] for obj in objects.get(\"Contents\", [])]\n",
    "        print(\"\\n📌 **S3 Files in Bucket `{bucket}`:**\")\n",
    "        if s3_files:\n",
    "            for file in s3_files[:10]:  # Show only first 10 files for readability\n",
    "                print(f\"   - {file}\")\n",
    "            if len(s3_files) > 10:\n",
    "                print(f\"   ... ({len(s3_files)} total files)\")\n",
    "        else:\n",
    "            print(\"   ❌ No files found.\")\n",
    "    except ClientError as e:\n",
    "        print(\"❌ Error listing S3 files:\", e)\n",
    "\n",
    "    # ✅ List Glue Databases\n",
    "    try:\n",
    "        glue_databases = glue_client.get_databases()[\"DatabaseList\"]\n",
    "        glue_db_names = [db[\"Name\"] for db in glue_databases]\n",
    "        print(\"\\n📌 **Glue Databases:**\")\n",
    "        if glue_db_names:\n",
    "            for db in glue_db_names:\n",
    "                print(f\"   - {db}\")\n",
    "        else:\n",
    "            print(\"   ❌ No Glue Databases found.\")\n",
    "    except ClientError as e:\n",
    "        print(\"❌ Error listing Glue databases:\", e)\n",
    "\n",
    "# ✅ Run AWS resource listing\n",
    "list_aws_resources()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
