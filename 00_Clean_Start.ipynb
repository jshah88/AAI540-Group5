{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e58ad78f-c08b-400a-b9b1-d8c1ac4ed44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Stored variables loaded (if available).\n",
      "\n",
      "🚀 **Starting Full Cleanup...**\n",
      "\n",
      "🔍 Checking if Feature Group `airline_delay_features_dev` exists...\n",
      "🚀 Feature Group `airline_delay_features_dev` found. Deleting...\n",
      "⏳ Waiting for Feature Group deletion...\n",
      "✅ Feature Group `airline_delay_features_dev` deleted successfully.\n",
      "🔍 Checking if Feature Group `airline_delay_features_prod` exists...\n",
      "🚀 Feature Group `airline_delay_features_prod` found. Deleting...\n",
      "⏳ Waiting for Feature Group deletion...\n",
      "✅ Feature Group `airline_delay_features_prod` deleted successfully.\n",
      "🗑️ Deleted model file: baseline_model.pkl\n",
      "🗑️ Deleted model file: baseline_model_logistic.pkl\n",
      "🧹 Removed `baseline_model_path` from %store.\n",
      "🧹 Removed `baseline_model_logistic_path` from %store.\n",
      "\n",
      "✅ **Cleanup completed successfully!**\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from botocore.exceptions import ClientError\n",
    "from pyathena import connect\n",
    "import time\n",
    "\n",
    "# ✅ Retrieve stored variables from previous notebooks\n",
    "stored_variables = [\"dev_feature_store_table\", \"prod_feature_store_table\", \n",
    "                    \"dev_feature_group_name\", \"prod_feature_group_name\",\n",
    "                    \"baseline_model_path\", \"baseline_model_logistic_path\",\n",
    "                    \"endpoint_name_single_request\"]\n",
    "\n",
    "for var in stored_variables:\n",
    "    try:\n",
    "        %store -r {var}\n",
    "    except KeyError:\n",
    "        print(f\"⚠️ Warning: `{var}` is not stored. Skipping...\")\n",
    "\n",
    "print(\"✅ Stored variables loaded (if available).\")\n",
    "\n",
    "# ✅ Initialize AWS Session\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# ✅ Use SageMaker's default bucket\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"flight-delay-prediction-xgboost\"  # ✅ Ensure this matches what was used in training\n",
    "\n",
    "# ✅ Set up Athena connection\n",
    "s3_staging_dir = f's3://{bucket}/athena-query-results/'\n",
    "conn = connect(s3_staging_dir=s3_staging_dir, region_name=region)\n",
    "\n",
    "# ✅ Define variables (check if they exist before using)\n",
    "ATHENA_DATABASE = \"sagemaker_featurestore\"\n",
    "ATHENA_TABLES_TO_DROP = [var for var in [dev_feature_store_table, prod_feature_store_table] if 'var' in locals()]\n",
    "GLUE_DATABASE_TO_DROP = \"db_airline_delay_cause\"\n",
    "\n",
    "# ✅ Initialize AWS clients\n",
    "s3_client = boto3.client(\"s3\")\n",
    "athena_client = boto3.client(\"athena\")\n",
    "sagemaker_client = boto3.client(\"sagemaker\", region_name=region)\n",
    "glue_client = boto3.client(\"glue\", region_name=region)\n",
    "\n",
    "# ✅ Feature Group Names (if they exist)\n",
    "DEV_FEATURE_GROUP_NAME = dev_feature_group_name if \"dev_feature_group_name\" in locals() else None\n",
    "PROD_FEATURE_GROUP_NAME = prod_feature_group_name if \"prod_feature_group_name\" in locals() else None\n",
    "\n",
    "# ✅ Delete Feature Groups\n",
    "def delete_feature_groups():\n",
    "    for feature_group_name in [DEV_FEATURE_GROUP_NAME, PROD_FEATURE_GROUP_NAME]:\n",
    "        if feature_group_name is None:\n",
    "            print(\"⚠️ Warning: Skipping Feature Group deletion (not defined).\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            print(f\"🔍 Checking if Feature Group `{feature_group_name}` exists...\")\n",
    "            existing_groups = sagemaker_client.list_feature_groups()['FeatureGroupSummaries']\n",
    "            existing_group_names = [fg['FeatureGroupName'] for fg in existing_groups]\n",
    "\n",
    "            if feature_group_name in existing_group_names:\n",
    "                print(f\"🚀 Feature Group `{feature_group_name}` found. Deleting...\")\n",
    "                sagemaker_client.delete_feature_group(FeatureGroupName=feature_group_name)\n",
    "\n",
    "                # Wait until deletion is complete\n",
    "                while True:\n",
    "                    existing_groups = sagemaker_client.list_feature_groups()['FeatureGroupSummaries']\n",
    "                    existing_group_names = [fg['FeatureGroupName'] for fg in existing_groups]\n",
    "                    if feature_group_name not in existing_group_names:\n",
    "                        print(f\"✅ Feature Group `{feature_group_name}` deleted successfully.\")\n",
    "                        break\n",
    "                    print(\"⏳ Waiting for Feature Group deletion...\")\n",
    "                    time.sleep(5)\n",
    "            else:\n",
    "                print(f\"✅ Feature Group `{feature_group_name}` does not exist. No deletion needed.\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error deleting Feature Group `{feature_group_name}`: {e}\")\n",
    "\n",
    "# ✅ Delete Model Files\n",
    "def delete_model_files():\n",
    "    for model_path in [baseline_model_path, baseline_model_logistic_path]:\n",
    "        if 'model_path' not in locals():\n",
    "            print(f\"⚠️ Warning: Model path `{model_path}` is not defined. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        if os.path.exists(model_path):\n",
    "            try:\n",
    "                os.remove(model_path)\n",
    "                print(f\"🗑️ Deleted model file: {model_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error deleting model file `{model_path}`: {e}\")\n",
    "        else:\n",
    "            print(f\"✅ Model file `{model_path}` does not exist. No deletion needed.\")\n",
    "\n",
    "# ✅ Delete SageMaker Endpoints\n",
    "def delete_sagemaker_endpoints():\n",
    "    if \"endpoint_name_single_request\" not in locals():\n",
    "        print(\"⚠️ Warning: No stored SageMaker endpoint name found. Skipping...\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        print(f\"🔍 Checking if SageMaker endpoint `{endpoint_name_single_request}` exists...\")\n",
    "        response = sagemaker_client.describe_endpoint(EndpointName=endpoint_name_single_request)\n",
    "        \n",
    "        if response[\"EndpointStatus\"] in [\"Creating\", \"InService\", \"RollingBack\", \"Updating\"]:\n",
    "            print(f\"🚀 Deleting SageMaker endpoint `{endpoint_name_single_request}`...\")\n",
    "            sagemaker_client.delete_endpoint(EndpointName=endpoint_name_single_request)\n",
    "\n",
    "            # Wait until the endpoint is deleted\n",
    "            while True:\n",
    "                try:\n",
    "                    response = sagemaker_client.describe_endpoint(EndpointName=endpoint_name_single_request)\n",
    "                    print(\"⏳ Waiting for endpoint deletion...\")\n",
    "                    time.sleep(5)\n",
    "                except ClientError as e:\n",
    "                    if \"Could not find endpoint\" in str(e):\n",
    "                        print(f\"✅ SageMaker endpoint `{endpoint_name_single_request}` deleted successfully.\")\n",
    "                        break\n",
    "                    else:\n",
    "                        print(f\"⚠️ Unexpected error: {e}\")\n",
    "                        break\n",
    "        else:\n",
    "            print(f\"✅ SageMaker endpoint `{endpoint_name_single_request}` does not exist or is already deleted.\")\n",
    "    except ClientError as e:\n",
    "        print(f\"⚠️ SageMaker endpoint `{endpoint_name_single_request}` not found. Skipping...\")\n",
    "\n",
    "# ✅ Delete Batch Transform Files in S3\n",
    "def delete_s3_batch_files():\n",
    "    batch_s3_path = f\"{prefix}/batch-output/\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"🔍 Checking S3 for batch transform files in `{batch_s3_path}`...\")\n",
    "        response = s3_client.list_objects_v2(Bucket=bucket, Prefix=batch_s3_path)\n",
    "        \n",
    "        if \"Contents\" in response:\n",
    "            print(f\"🚀 Deleting all batch transform files in `{batch_s3_path}`...\")\n",
    "            objects_to_delete = [{\"Key\": obj[\"Key\"]} for obj in response[\"Contents\"]]\n",
    "            s3_client.delete_objects(Bucket=bucket, Delete={\"Objects\": objects_to_delete})\n",
    "            print(f\"✅ Batch transform files deleted successfully.\")\n",
    "        else:\n",
    "            print(f\"✅ No batch transform files found. Skipping deletion.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error deleting batch files: {e}\")\n",
    "\n",
    "# ✅ Remove Stored Variables\n",
    "def clear_stored_variables():\n",
    "    for var in [\"baseline_model_path\", \"baseline_model_logistic_path\", \"endpoint_name_single_request\"]:\n",
    "        try:\n",
    "            %store -d {var}\n",
    "            print(f\"🧹 Removed `{var}` from %store.\")\n",
    "        except Exception:\n",
    "            print(f\"⚠️ `{var}` was not in %store. Skipping...\")\n",
    "\n",
    "# ✅ Run cleanup\n",
    "def clean_state():\n",
    "    print(\"\\n🚀 **Starting Full Cleanup...**\\n\")\n",
    "    delete_feature_groups()\n",
    "    delete_model_files()\n",
    "    delete_sagemaker_endpoints()\n",
    "    delete_s3_batch_files()  # ✅ Added batch output deletion\n",
    "    clear_stored_variables()\n",
    "    print(\"\\n✅ **Cleanup completed successfully!**\")\n",
    "\n",
    "# ✅ Execute the cleanup function\n",
    "clean_state()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe1e013-632f-4f86-8001-1b5ffe1a741b",
   "metadata": {},
   "source": [
    "# Use code below to check what else is on your system and whether something was left behind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cacef9e-d7bd-4026-888c-5f9faee81daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 📌 AWS Resource Overview ---\n",
      "\n",
      "📌 **Athena Databases:**\n",
      "   - default\n",
      "\n",
      "📌 **Tables in Athena Database: `default`**\n",
      "   ❌ No tables found in this database.\n",
      "\n",
      "📌 **Feature Store Groups:**\n",
      "   ❌ No Feature Groups found.\n",
      "\n",
      "📌 **S3 Files in Bucket `{bucket}`:**\n",
      "   ❌ No files found.\n",
      "\n",
      "📌 **Glue Databases:**\n",
      "   - default\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "from pyathena import connect\n",
    "\n",
    "# ✅ Initialize AWS Session\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "sagemaker_session = boto3.Session()\n",
    "\n",
    "# ✅ Use SageMaker's default bucket\n",
    "bucket = sagemaker_session.client(\"s3\").list_buckets()[\"Buckets\"][0][\"Name\"]\n",
    "\n",
    "# ✅ Set up Athena connection\n",
    "s3_staging_dir = f's3://{bucket}/athena-query-results/'\n",
    "conn = connect(s3_staging_dir=s3_staging_dir, region_name=region)\n",
    "\n",
    "# ✅ Initialize AWS clients\n",
    "s3_client = boto3.client(\"s3\", region_name=region)\n",
    "athena_client = boto3.client(\"athena\", region_name=region)\n",
    "sagemaker_client = boto3.client(\"sagemaker\", region_name=region)\n",
    "glue_client = boto3.client(\"glue\", region_name=region)\n",
    "\n",
    "# ✅ Function to list AWS resources\n",
    "def list_aws_resources():\n",
    "    print(\"\\n--- 📌 AWS Resource Overview ---\")\n",
    "    \n",
    "    # ✅ List Athena Databases\n",
    "    try:\n",
    "        databases = athena_client.list_databases(CatalogName=\"AwsDataCatalog\")[\"DatabaseList\"]\n",
    "        database_names = [db[\"Name\"] for db in databases]\n",
    "        print(\"\\n📌 **Athena Databases:**\")\n",
    "        for db in database_names:\n",
    "            print(f\"   - {db}\")\n",
    "    except ClientError as e:\n",
    "        print(\"❌ Error listing Athena databases:\", e)\n",
    "        database_names = []  # Ensure it doesn't break the next step\n",
    "\n",
    "    # ✅ List Athena Tables Per Database\n",
    "    for database in database_names:\n",
    "        try:\n",
    "            tables = athena_client.list_table_metadata(CatalogName=\"AwsDataCatalog\", DatabaseName=database)[\"TableMetadataList\"]\n",
    "            table_names = [table[\"Name\"] for table in tables]\n",
    "\n",
    "            print(f\"\\n📌 **Tables in Athena Database: `{database}`**\")\n",
    "            if table_names:\n",
    "                for table in table_names:\n",
    "                    print(f\"   - {table}\")\n",
    "            else:\n",
    "                print(\"   ❌ No tables found in this database.\")\n",
    "\n",
    "        except ClientError as e:\n",
    "            print(f\"❌ Error listing tables in `{database}`:\", e)\n",
    "\n",
    "    # ✅ List Feature Store Groups\n",
    "    try:\n",
    "        feature_groups = sagemaker_client.list_feature_groups()[\"FeatureGroupSummaries\"]\n",
    "        feature_group_names = [fg[\"FeatureGroupName\"] for fg in feature_groups]\n",
    "        print(\"\\n📌 **Feature Store Groups:**\")\n",
    "        if feature_group_names:\n",
    "            for fg in feature_group_names:\n",
    "                print(f\"   - {fg}\")\n",
    "        else:\n",
    "            print(\"   ❌ No Feature Groups found.\")\n",
    "    except ClientError as e:\n",
    "        print(\"❌ Error listing Feature Groups:\", e)\n",
    "\n",
    "    # ✅ List S3 Files\n",
    "    try:\n",
    "        objects = s3_client.list_objects_v2(Bucket=bucket)\n",
    "        s3_files = [obj[\"Key\"] for obj in objects.get(\"Contents\", [])]\n",
    "        print(\"\\n📌 **S3 Files in Bucket `{bucket}`:**\")\n",
    "        if s3_files:\n",
    "            for file in s3_files[:10]:  # Show only first 10 files for readability\n",
    "                print(f\"   - {file}\")\n",
    "            if len(s3_files) > 10:\n",
    "                print(f\"   ... ({len(s3_files)} total files)\")\n",
    "        else:\n",
    "            print(\"   ❌ No files found.\")\n",
    "    except ClientError as e:\n",
    "        print(\"❌ Error listing S3 files:\", e)\n",
    "\n",
    "    # ✅ List Glue Databases\n",
    "    try:\n",
    "        glue_databases = glue_client.get_databases()[\"DatabaseList\"]\n",
    "        glue_db_names = [db[\"Name\"] for db in glue_databases]\n",
    "        print(\"\\n📌 **Glue Databases:**\")\n",
    "        if glue_db_names:\n",
    "            for db in glue_db_names:\n",
    "                print(f\"   - {db}\")\n",
    "        else:\n",
    "            print(\"   ❌ No Glue Databases found.\")\n",
    "    except ClientError as e:\n",
    "        print(\"❌ Error listing Glue databases:\", e)\n",
    "\n",
    "# ✅ Run AWS resource listing\n",
    "list_aws_resources()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
