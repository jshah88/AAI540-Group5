{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34b1c3f5-d22c-406b-8c4d-bf93e9a8ca85",
   "metadata": {},
   "source": [
    "# Query values from development database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "568fb9c8-07c1-4c02-9c4f-fa29b530086c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3771/475678379.py:22: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  dev_data_df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  month carrier airport  arr_flights  arr_del15  carrier_ct  \\\n",
      "0  2004      1      DL     PBI          650        126          21   \n",
      "1  2004      1      DL     PDX          314         61          14   \n",
      "2  2004      1      DL     PHL          513         97          27   \n",
      "3  2004      1      DL     PHX          334         78          20   \n",
      "4  2004      1      DL     PIT          217         47           8   \n",
      "\n",
      "   weather_ct  nas_ct  security_ct  ...  arr_cancelled  arr_diverted  \\\n",
      "0           6      51            1  ...              4             0   \n",
      "1           2      34            0  ...             30             3   \n",
      "2           0      51            0  ...             15             0   \n",
      "3           2      39            0  ...              3             1   \n",
      "4           0      21            0  ...              4             1   \n",
      "\n",
      "   arr_delay  carrier_delay  weather_delay  nas_delay  security_delay  \\\n",
      "0       5425            881            397       2016              15   \n",
      "1       2801            478            239       1365               0   \n",
      "2       4261           1150             16       2286               0   \n",
      "3       3400           1159            166       1295               0   \n",
      "4       1737            350             28        522               0   \n",
      "\n",
      "   late_aircraft_delay  delay_rate  on_time  \n",
      "0                 2116   19.384615        0  \n",
      "1                  719   19.426752        0  \n",
      "2                  809   18.908382        0  \n",
      "3                  780   23.353292        0  \n",
      "4                  837   21.658987        0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from pyathena import connect\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Initialize AWS Session\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role_arn = sagemaker.get_execution_role()\n",
    "\n",
    "# Use SageMaker's default bucket\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "# Set up Athena connection\n",
    "s3_staging_dir = f's3://{bucket}/athena-query-results/'\n",
    "conn = connect(s3_staging_dir=s3_staging_dir, region_name=region)\n",
    "\n",
    "# Query development data\n",
    "query = \"SELECT * FROM db_airline_delay_cause.development_data;\"  # Adjust limit easily\n",
    "dev_data_df = pd.read_sql(query, conn)\n",
    "\n",
    "# Display the first few rows\n",
    "print(dev_data_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332a2011-8095-495d-ba5d-9194754d176a",
   "metadata": {},
   "source": [
    "# Preprocess Data and Cast/Convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0a70edd-f6a5-42e6-8436-99d83134abd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data Preprocessing Complete. Ready for Feature Store Upload!\n",
      "year                            int64\n",
      "month                           int64\n",
      "carrier                string[python]\n",
      "airport                string[python]\n",
      "arr_flights                     int64\n",
      "arr_del15                       int64\n",
      "carrier_ct                      int64\n",
      "weather_ct                      int64\n",
      "nas_ct                          int64\n",
      "security_ct                     int64\n",
      "late_aircraft_ct                int64\n",
      "arr_cancelled                   int64\n",
      "arr_diverted                    int64\n",
      "arr_delay                       int64\n",
      "carrier_delay                   int64\n",
      "weather_delay                   int64\n",
      "nas_delay                       int64\n",
      "security_delay                  int64\n",
      "late_aircraft_delay             int64\n",
      "delay_rate                      int64\n",
      "on_time                         int64\n",
      "event_time                    float64\n",
      "record_id              string[python]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# ‚úÖ Convert categorical features to `string`\n",
    "def cast_object_to_string(data_frame):\n",
    "    for label in data_frame.columns:\n",
    "        if data_frame.dtypes[label] == \"object\":\n",
    "            data_frame[label] = data_frame[label].astype(\"str\").astype(\"string\")\n",
    "\n",
    "cast_object_to_string(dev_data_df)\n",
    "\n",
    "# ‚úÖ Convert all numeric columns to `int64` (except `event_time`)\n",
    "for col in dev_data_df.select_dtypes(include=['int', 'float']).columns:\n",
    "    if col not in [\"event_time\"]:\n",
    "        dev_data_df[col] = dev_data_df[col].astype(\"int64\")\n",
    "\n",
    "# ‚úÖ Feature Engineering: Binary 'on_time' column\n",
    "def is_on_time(row):\n",
    "    return 1 if row['arr_del15'] == 0 and row['arr_cancelled'] == 0 else 0\n",
    "\n",
    "dev_data_df['on_time'] = dev_data_df.apply(is_on_time, axis=1)\n",
    "\n",
    "# ‚úÖ Ensure `event_time` is a FLOAT UNIX timestamp\n",
    "current_time_sec = int(round(time.time()))\n",
    "dev_data_df['event_time'] = pd.Series([current_time_sec] * len(dev_data_df), dtype=\"float64\")\n",
    "\n",
    "# ‚úÖ Ensure `record_id` is a unique string identifier\n",
    "dev_data_df['record_id'] = dev_data_df.index.astype(\"string\")\n",
    "\n",
    "print(\"‚úÖ Data Preprocessing Complete. Ready for Feature Store Upload!\")\n",
    "print(dev_data_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7671742a-75af-43d4-b59b-135a117875aa",
   "metadata": {},
   "source": [
    "# Create Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9d52aba-2689-4214-905d-68b7cc171391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking if Feature Group 'airline_delay_features' exists...\n",
      "‚úÖ Feature Group 'airline_delay_features' does not exist. No deletion needed.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import time\n",
    "\n",
    "# Set AWS region and feature group name\n",
    "region = \"us-east-1\"  # Update if needed\n",
    "feature_group_name = \"airline_delay_features\"\n",
    "\n",
    "# Initialize SageMaker client\n",
    "sagemaker_client = boto3.client('sagemaker', region_name=region)\n",
    "\n",
    "# Delete the Feature Group if it exists\n",
    "try:\n",
    "    print(f\"üîç Checking if Feature Group '{feature_group_name}' exists...\")\n",
    "\n",
    "    # Check if the feature group exists\n",
    "    existing_groups = sagemaker_client.list_feature_groups()['FeatureGroupSummaries']\n",
    "    existing_group_names = [fg['FeatureGroupName'] for fg in existing_groups]\n",
    "\n",
    "    if feature_group_name in existing_group_names:\n",
    "        print(f\"üöÄ Feature Group '{feature_group_name}' found. Deleting...\")\n",
    "\n",
    "        # Delete the feature group\n",
    "        sagemaker_client.delete_feature_group(FeatureGroupName=feature_group_name)\n",
    "\n",
    "        # Wait for deletion to complete\n",
    "        while True:\n",
    "            existing_groups = sagemaker_client.list_feature_groups()['FeatureGroupSummaries']\n",
    "            existing_group_names = [fg['FeatureGroupName'] for fg in existing_groups]\n",
    "\n",
    "            if feature_group_name not in existing_group_names:\n",
    "                print(f\"‚úÖ Feature Group '{feature_group_name}' deleted successfully.\")\n",
    "                break\n",
    "\n",
    "            print(\"‚è≥ Waiting for Feature Group deletion...\")\n",
    "            time.sleep(5)\n",
    "\n",
    "    else:\n",
    "        print(f\"‚úÖ Feature Group '{feature_group_name}' does not exist. No deletion needed.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error deleting Feature Group: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea63798e-184e-47ec-a603-8fc82ef8afcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::607916531205:role/LabRole'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "803938a7-7559-4c38-a742-91cbbd91ee4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Feature Group 'airline_delay_features' does NOT exist! Creating it now.\n",
      "‚úÖ Feature Group 'airline_delay_features' created successfully.\n",
      "‚è≥ Waiting for Feature Group to become active...\n",
      "‚è≥ Current Feature Group status: Creating\n",
      "‚è≥ Current Feature Group status: Creating\n",
      "‚è≥ Current Feature Group status: Creating\n",
      "‚è≥ Current Feature Group status: Creating\n",
      "‚è≥ Current Feature Group status: Created\n",
      "‚úÖ Feature Group is now fully ready!\n",
      "‚è≥ Waiting an additional 10 seconds for stability...\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "# Define the Feature Group name\n",
    "feature_group_name = \"airline_delay_features\"\n",
    "\n",
    "# Initialize SageMaker client\n",
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "# ‚úÖ Step 1: Check if Feature Group Exists\n",
    "existing_groups = sagemaker_client.list_feature_groups()['FeatureGroupSummaries']\n",
    "existing_group_names = [fg['FeatureGroupName'] for fg in existing_groups]\n",
    "\n",
    "if feature_group_name in existing_group_names:\n",
    "    print(f\"‚úÖ Feature Group '{feature_group_name}' already exists.\")\n",
    "else:\n",
    "    print(f\"üöÄ Feature Group '{feature_group_name}' does NOT exist! Creating it now.\")\n",
    "\n",
    "    # ‚úÖ Step 2: Define Feature Group Schema\n",
    "    s3_uri = f\"s3://{bucket}/feature-store/\"\n",
    "\n",
    "    feature_group_definition = {\n",
    "        \"FeatureGroupName\": feature_group_name,\n",
    "        \"RecordIdentifierFeatureName\": \"record_id\",\n",
    "        \"EventTimeFeatureName\": \"event_time\",\n",
    "        \"FeatureDefinitions\": [\n",
    "            {\"FeatureName\": \"event_time\", \"FeatureType\": \"Fractional\"}\n",
    "        ] + [\n",
    "            {\n",
    "                \"FeatureName\": col,\n",
    "                \"FeatureType\": \"String\" if dev_data_df[col].dtype == \"string\" else \"Integral\"\n",
    "            }\n",
    "            for col in dev_data_df.columns if col != \"event_time\"\n",
    "        ],\n",
    "        \"OnlineStoreConfig\": {\"EnableOnlineStore\": True},\n",
    "        \"OfflineStoreConfig\": {\n",
    "            \"S3StorageConfig\": {\"S3Uri\": s3_uri},\n",
    "            \"DisableGlueTableCreation\": False,\n",
    "        },\n",
    "        \"RoleArn\": role_arn,\n",
    "    }\n",
    "\n",
    "    # ‚úÖ Step 3: Create Feature Group\n",
    "    try:\n",
    "        sagemaker_client.create_feature_group(**feature_group_definition)\n",
    "        print(f\"‚úÖ Feature Group '{feature_group_name}' created successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creating Feature Group: {e}\")\n",
    "        exit()\n",
    "\n",
    "# ‚úÖ Step 4: Wait Until Feature Group is Ready\n",
    "print(\"‚è≥ Waiting for Feature Group to become active...\")\n",
    "while True:\n",
    "    try:\n",
    "        status_response = sagemaker_client.describe_feature_group(FeatureGroupName=feature_group_name)\n",
    "        status = status_response[\"FeatureGroupStatus\"]\n",
    "        print(f\"‚è≥ Current Feature Group status: {status}\")\n",
    "\n",
    "        if status == \"Created\":\n",
    "            print(\"‚úÖ Feature Group is now fully ready!\")\n",
    "            break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error checking Feature Group status: {e}\")\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "print(\"‚è≥ Waiting an additional 10 seconds for stability...\")\n",
    "time.sleep(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ddd28f-f6fd-41f8-97bb-befca987a06e",
   "metadata": {},
   "source": [
    "# Record insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2070bd0-639f-43cb-b911-f5d52dd0e38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully inserted one record into Feature Store!\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "import boto3\n",
    "\n",
    "# Initialize Feature Store Runtime client\n",
    "featurestore_runtime = boto3.client(\"sagemaker-featurestore-runtime\")\n",
    "\n",
    "# ‚úÖ Convert event_time to UNIX timestamp (float64)\n",
    "dev_data_df[\"event_time\"] = time.time()\n",
    "\n",
    "# ‚úÖ Select one row and convert to Feature Store format\n",
    "single_record = dev_data_df.iloc[0].to_dict()\n",
    "\n",
    "# ‚úÖ Ensure event_time and record_id are included\n",
    "record = {\n",
    "    \"FeatureGroupName\": feature_group_name,\n",
    "    \"Record\": [\n",
    "        {\"FeatureName\": key, \"ValueAsString\": str(value)} for key, value in single_record.items()\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ‚úÖ Insert single record into Feature Store\n",
    "featurestore_runtime.put_record(**record)\n",
    "\n",
    "print(\"‚úÖ Successfully inserted one record into Feature Store!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c313ba67-faef-40e2-bc7f-c91ffee45a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Waiting for the Feature Group to be available in Glue...\n",
      "‚úÖ Feature Group is now active!\n",
      "‚úÖ Feature Store table registered in Glue: airline_delay_features_1739141540\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import time\n",
    "\n",
    "# Initialize SageMaker client\n",
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "# ‚úÖ Describe Feature Group to Get the Table Name\n",
    "def get_feature_store_table_name(feature_group_name):\n",
    "    print(\"‚è≥ Waiting for the Feature Group to be available in Glue...\")\n",
    "    \n",
    "    # Wait for Feature Group to be created\n",
    "    while True:\n",
    "        response = sagemaker_client.describe_feature_group(FeatureGroupName=feature_group_name)\n",
    "        status = response[\"FeatureGroupStatus\"]\n",
    "        if status == \"Created\":\n",
    "            print(\"‚úÖ Feature Group is now active!\")\n",
    "            break\n",
    "        print(f\"‚è≥ Current status: {status}, retrying in 5 seconds...\")\n",
    "        time.sleep(5)\n",
    "    \n",
    "    # Retrieve Glue Table Name\n",
    "    table_name = response[\"OfflineStoreConfig\"][\"DataCatalogConfig\"][\"TableName\"]\n",
    "    print(f\"‚úÖ Feature Store table registered in Glue: {table_name}\")\n",
    "    \n",
    "    return table_name\n",
    "\n",
    "# Call this function **after creating the Feature Store**\n",
    "correct_feature_store_table = get_feature_store_table_name(feature_group_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef954f8c-9b00-4833-8876-da153f9783c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3771/286044812.py:9: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  offline_record_df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Record Found in Feature Store (Offline Store via Athena):\n",
      "     event_time  year  month carrier airport  arr_flights  arr_del15  \\\n",
      "0  1.739142e+09  2004      1      DL     PBI          650        126   \n",
      "\n",
      "   carrier_ct  weather_ct  nas_ct  ...  weather_delay  nas_delay  \\\n",
      "0          21           6      51  ...            397       2016   \n",
      "\n",
      "   security_delay  late_aircraft_delay  delay_rate  on_time  record_id  \\\n",
      "0              15                 2116          19        0          0   \n",
      "\n",
      "               write_time  api_invocation_time  is_deleted  \n",
      "0 2025-02-09 22:59:43.943  2025-02-09 22:54:44       False  \n",
      "\n",
      "[1 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# Query to retrieve record from offline store (Athena)\n",
    "query = f\"\"\"\n",
    "SELECT * FROM \"sagemaker_featurestore\".\"{correct_feature_store_table}\"\n",
    "WHERE record_id = '{single_record[\"record_id\"]}'\n",
    "LIMIT 1;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query using Pandas\n",
    "offline_record_df = pd.read_sql(query, conn)\n",
    "\n",
    "# ‚úÖ Check if record exists\n",
    "if not offline_record_df.empty:\n",
    "    print(\"‚úÖ Record Found in Feature Store (Offline Store via Athena):\")\n",
    "    print(offline_record_df)\n",
    "else:\n",
    "    print(\"‚ùå Record not found in Offline Store!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4e5446-05bc-4d86-984b-38a5b5730076",
   "metadata": {},
   "source": [
    "# Inserting All Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ea9f6eb-fcde-4513-b215-858beeea37af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ All records successfully ingested into Feature Store!\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Bulk ingestion using the simpler `ingest()` method\n",
    "feature_group.ingest(\n",
    "    data_frame=dev_data_df[1:],  # Use the full dataset except first entry\n",
    "    max_workers=5,  # Controls parallel processing\n",
    "    wait=True  # Waits for the ingestion to complete\n",
    ")\n",
    "\n",
    "print(\"üöÄ All records successfully ingested into Feature Store!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f709b47-cab0-4ecc-a321-87b237665462",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3771/2454169074.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  record_count_df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Current records in Feature Store: 198830, Total Records: 198829\n",
      "Note: If numbers don't match, uploads are likely still completing. Wait for a minute before running this cell again\n"
     ]
    }
   ],
   "source": [
    "# Run this to confirm all records are in feature store\n",
    "query = f\"\"\"\n",
    "SELECT COUNT(*) FROM \"sagemaker_featurestore\".\"{correct_feature_store_table}\";\n",
    "\"\"\"\n",
    "\n",
    "# ‚úÖ Execute Athena query using Pandas\n",
    "record_count_df = pd.read_sql(query, conn)\n",
    "\n",
    "# ‚úÖ Print the current number of records uploaded\n",
    "print(f\"üîç Current records in Feature Store: {record_count_df.iloc[0, 0]}, Total Records: {len(dev_data_df)}\")\n",
    "print(f\"Note: If numbers don't match, uploads are likely still completing. Wait for a minute before running this cell again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b02259-b6e0-4214-adbf-b0b7788f2bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
